# -*- coding: utf-8 -*-
"""Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dQvTpn7uX1o1FD1pHvZJAWPnMhc0XhPy

**IMPORTING LIBRARIES**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import torch
import torch.nn as nn
import os
import  PIL
import cv2 as cv
from PIL import Image
from torchvision import transforms
from torch.utils.data import Dataset,DataLoader
import glob
from skimage.color import rgb2lab,lab2rgb
import tqdm

"""# **`MODEL`**:
*   `GENERATOR`
*   `DISCRIMINATOR`
"""

class conv_block(nn.Module):
  def __init__(self,inchannels,outchannels,batchnorm=False,up=True,Dropout=False):
    super(conv_block,self).__init__()
    # kernel size=(4,4), stride=2, padding =1
    # as we will be using batchnorm so we will be keeping off our bias term in convolution.
    self.block1=nn.Sequential(nn.Conv2d(inchannels,outchannels,4,2,1,bias=False) if up==False else nn.ConvTranspose2d(inchannels,outchannels,4,2,1,bias=False))
    self.batch=batchnorm
    self.drop=Dropout
    if batchnorm:
      self.block2=nn.BatchNorm2d(outchannels)
     # decoder
    if up==True:  
      self.block3=nn.ReLU()

    # encoder  
    else:    
      self.block3=nn.LeakyReLU(0.2)
    if Dropout:
      self.block4=nn.Dropout(0.5)

  def forward(self,x):
    x=self.block1(x)
    if self.batch:
      x=self.block2(x)
    x=self.block3(x)
    if self.drop==True:
      return self.block4(x)
    else:
      return x

class Generator(nn.Module):
  def __init__(self,inchannels=1):
    super(Generator,self).__init__()
    #encoder unet
    self.down1=conv_block(1,64,False,False,False)
    self.down2=conv_block(64,128,True,False,False)
    self.down3=conv_block(128,256,True,False,False)
    self.down4=conv_block(256,512,True,False,False)
    self.down5=conv_block(512,512,True,False,False)
    self.down6=conv_block(512,512,True,False,False)
    self.down7=conv_block(512,512,True,False,False)
    self.bottleneck=nn.Sequential(nn.Conv2d(512,512,4,2,1),nn.LeakyReLU(0.2))

    #decoder unet
    self.up1=conv_block(512,512,True,True,True)
    self.up2=conv_block(1024,512,True,True,True)
    self.up3=conv_block(1024,512,True,True,True)
    self.up4=conv_block(1024,512,True,True,False)
    self.up5=conv_block(1024,256,True,True,False)
    self.up6=conv_block(512,128,True,True,False)
    self.up7=conv_block(256,64,True,True,False)
    self.last=nn.Sequential(nn.ConvTranspose2d(128,2,4,2,1),nn.Tanh())

  def forward(self,x):
    x1=self.down1(x)   # concatenation of ith and (16-i)th layer.
    x2=self.down2(x1)
    x3=self.down3(x2)
    x4=self.down4(x3)
    x5=self.down5(x4)
    x6=self.down6(x5)
    x7=self.down7(x6)
    x8=self.bottleneck(x7)
    u1=self.up1(x8)
    u2=self.up2(torch.concat([u1,x7],1))
    u3=self.up3(torch.concat([u2,x6],1))
    u4=self.up4(torch.concat([u3,x5],1))
    u5=self.up5(torch.concat([u4,x4],1))
    u6=self.up6(torch.concat([u5,x3],1))
    u7=self.up7(torch.concat([u6,x2],1))
    u8=self.last(torch.concat([u7,x1],1))

    return u8

class discriminator_block(nn.Module):
  def __init__(self,inchannels,outchannels,stride):
    super(discriminator_block,self).__init__()
    self.block=nn.Sequential(nn.Conv2d( inchannels,outchannels,4,stride,1,bias=False),nn.BatchNorm2d(outchannels),nn.LeakyReLU(0.2))

  def forward(self,x):
    return self.block(x)

class discriminator(nn.Module):
  def __init__(self,inchannels=3):
    super(discriminator,self).__init__()
    # at initial stage we will get two inputs each having 3 channels
    self.block1=nn.Sequential(nn.Conv2d(3,64,4,2,1),nn.LeakyReLU(0.2)) 
    self.block2=discriminator_block(64,128,2)
    self.block3=discriminator_block(128,256,2)
    self.block4=discriminator_block(256,512,1)
    self.block5=nn.Conv2d(512,1,4,1,1)
  def forward(self,y):
    x=self.block1(y)
    #print(x.shape)
    x=self.block2(x)
    #print(x.shape)
    x=self.block3(x)
    #print(x.shape)
    x=self.block4(x)
    #print(x.shape)
    return self.block5(x)

"""`Using fastai api to get the data:`
*   `pip install-U fastai.`
*   `importing required utilities like untar_data,URLs to download image file paths.`
*   `splitting 10,000 images into 8000,2000:(train,test)`
*   `Maintain a fixed seed so that every time same list of image paths get downloaded`
"""

!pip install -U fastai

from fastai.data.external import untar_data, URLs
coco_path = untar_data(URLs.COCO_SAMPLE)
coco_path = str(coco_path) + "/train_sample"
paths = glob.glob(coco_path + "/*.jpg") #  Grabbing all the image file names
np.random.seed(123)
paths_subset = np.random.choice(paths, 10_000, replace=False) # choosing 1000 images randomly
rand_idxs = np.random.permutation(10_000)
train_idxs = rand_idxs[:8000] # choosing the first 8000 as training set
val_idxs = rand_idxs[8000:] # choosing last 2000 as validation set
train_paths = paths_subset[train_idxs]
val_paths = paths_subset[val_idxs]
print(len(train_paths), len(val_paths))

"""**DATA** **LOADER** 
* `Using Dataset Utility of pytorch`
* `Input:List of Image file paths`
* `Output:Resized (3,256,256) Image, and corresponding L   channel from LAB color space.`    

"""

class data_loading(Dataset):
  def __init__(self,filelist):
    self.filelist=filelist# here we get all the images file path

  def __len__(self):
    return len(self.filelist)

  def __getitem__(self,index):
    self.images=self.filelist[index]  # getting the path of image  to be loaded
    self.img2=Image.open(self.images).convert('RGB')  # reading numpy values
    self.img=transforms.Resize((256, 256),  Image.BICUBIC)(self.img2) # ground_truth image # (bacthsize,channels,height,width)
    self.img2= rgb2lab(self.img).astype("float32") # Converting RGB to L*a*b
    self.img_lab= transforms.ToTensor()(self.img2) 
    self.L=self.img_lab[[0], ...] / 50. - 1. # Between -1 and 1
    self.ab =self.img_lab[[1, 2], ...] / 110. # Between -1 and 1
        
    return {'L': self.L, 'ab': self.ab}

batch_size = 16 # size of the batch of images...   # no of workers in the gpu 
epochs = 20
L1_lambda = 100.0
in_w = in_h = 256  # image size.
c_dim = 3  # no. of channels
shuffle=True
num_workers=2

train_dataset=data_loading(train_paths)
valid_dataset=data_loading(val_paths)
train_loader=DataLoader(train_dataset,batch_size,shuffle,num_workers=num_workers)
valid_loader=DataLoader(valid_dataset,batch_size,shuffle,num_workers=num_workers)

"""* `Activating CUDA if available ,for GPU usage`
* `Loading Model onto the available device`
"""

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")   
device

G = Generator().to(device)
D = discriminator().to(device)

G_optimizer = torch.optim.Adam(G.parameters(), lr=2e-4,betas=(0.5,0.999))
D_optimizer = torch.optim.Adam(D.parameters(), lr=2e-4,betas=(0.5,0.999))

criterion_gan = nn.BCEWithLogitsLoss()
criterion_pixelwise = nn.L1Loss()

"""`Restoring past weights and optimizers`"""

checkpoints=torch.load('/content/drive/MyDrive/checkpoint/model_status')

checkpoint=True
if checkpoint:
    G.load_state_dict(checkpoints["G_state"])
    G_optimizer.load_state_dict(checkpoints["Goptimizer"])
    D.load_state_dict(checkpoints["D_state"])
    D_optimizer.load_state_dict(checkpoints["Doptimizer"])
    discriminator_loss=[]
    Generator_loss=[]
    G_agg=0
    d_agg=0

"""

*  `Epochs times Model will run through complete training data.`
*  `During each epoch at every iteration data is loaded in batches.`
*  `In each iteration,first Discriminator is processed through then Generator`



"""

for ep in range(epochs):
  
  for i, data in enumerate(train_loader):
    
    L = data['L'].to(device) # L-channel to be fed as input to generator.
    ab = data['ab'].to(device)  # R-G-B channel ground truth image.

    b_size = L.shape[0]

    real_class = torch.ones(b_size,1,30,30).to(device)
    fake_class = torch.zeros(b_size,1,30,30).to(device)
  
    #z=torch.randn(torch.concat([L,ab],1).shape).to(device)
  #train_D
    D_optimizer.zero_grad()
    
    fake_ab=G(L) # we getting the fake output. (batchsize,2,256,256)
    D_fake = D(torch.concat([L,fake_ab],1).detach())
    D_fake_loss=criterion_gan(D_fake,fake_class) # computes log(1-D(G(x)))

   
    D_real=D(torch.concat([L,ab],1))
    D_real_loss=criterion_gan(D_real,real_class) # computes log(D(y))
    
    Total_loss=0.5*(D_real_loss+D_fake_loss)
    d_agg=Total_loss
    Total_loss.backward()
  
    D_optimizer.step()

   #Train G
    G_optimizer.zero_grad()

    fake_ab = G(L)
    fake_patch=D(torch.concat([L,fake_ab],1))
    fake_gan_loss=criterion_gan(fake_patch,real_class) #computes log(D(G(x)))

    L1_loss = criterion_pixelwise(torch.concat([L,fake_ab],1),torch.concat([L,ab],1))
    G_loss = fake_gan_loss + L1_lambda*L1_loss
    G_agg=G_loss
    G_loss.backward()  # calculating gradients
  
    G_optimizer.step()  # generator architecture parameteres are getting updated
    
    discriminator_loss.append(d_agg)
    Generator_loss.append(G_agg)

  
  print("epochs done",ep)

"""`Converting the predicted images to RGB color space`"""

def lab_to_rgb(L, ab):
    """
    Takes a batch of images
    """
    
    L = (L + 1.) * 50.
    ab = ab * 110.
    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().detach().numpy()
    rgb_imgs = []
    for img in Lab:
        img_rgb = lab2rgb(img)
        rgb_imgs.append(img_rgb)
    return np.stack(rgb_imgs, axis=0)

"""`Showing predicted Image Samples`"""

def showimages(G,valid_gen):
    data_valid=next(iter(valid_gen))
    valid_L=data_valid['L']
    valid_ab=data_valid['ab']
    valid_L=valid_L.to(device)
    valid_ab=valid_ab.to(device)
    G.eval()
    with torch.no_grad():
        valid_pred=G(valid_L)
        valid_img=lab_to_rgb(valid_L,valid_pred)
        real_img=lab_to_rgb(valid_L,valid_ab)
        plt.figure(figsize=(12,10))
        for i in range(15):
            plt.subplot(3, 5, i + 1)
            if i<5:
                plt.imshow(valid_L[i][0].cpu().detach().numpy(),cmap='bone')
            elif 5<=i and i<10 :
                plt.imshow(valid_img[i-5])
            else:
                plt.imshow(real_img[i-10])
        plt.axis('off')
        
    G.train()

showimages(G,valid_loader)

showimages(G,train_loader)

di=[]
ge=[]
for i in discriminator_loss:
  di.append(i.cpu().detach().numpy())
  
for i in Generator_loss:
  ge.append(i.cpu().detach().numpy())

checkpoints={"G_state":G.state_dict(),"D_state":D.state_dict(),"Goptimizer":G_optimizer.state_dict(),"Doptimizer":D_optimizer.state_dict()}
torch.save(checkpoints,'/content/drive/MyDrive/checkpoint/model_status')

df=pd.DataFrame(di,columns=['discriminator'])
df['Generator']=pd.Series(ge)
df_=pd.read_csv('/content/drive/MyDrive/checkpoint/losses.csv')
df2=df_.drop(labels='Unnamed: 0',axis=1)
df3=pd.concat([df2,df],axis=0)


get1=list(df3['discriminator'])
get2=list(df3['Generator'])

plt.figure(figsize=(10,12))
plt.plot(get1)
plt.plot(get2)
plt.legend(['discriminator_loss','generator_loss'])

df3.to_csv('/content/drive/MyDrive/checkpoint/losses.csv')




## link to load weights of trained Generator,Discrmintaor,Optimizers..
https://drive.google.com/drive/folders/1nuA7yRyvBkrVdbDkys1MVvvMLcOTwF40?usp=sharing